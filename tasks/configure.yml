---

# Needed to ensure some services start properly
- name: Set hostname
  become: yes
  lineinfile:
    dest: /etc/hosts
    line: "127.0.0.1 {{ ansible_hostname }}"
  notify:
    - restart kafka

- name: Copy AWS autodiscover script
  become: yes
  become_user: "{{ kafka.user }}"
  copy:
    src: aws_cluster_autodiscover
    dest: "/home/{{ kafka.user }}/bin/aws_cluster_autodiscover"
    owner: "{{ kafka.user }}"
    group: "{{ kafka.group }}"
    mode: 0750
  when: kafka.aws_cluster_autodiscover.enabled

- name: Run AWS autodiscover script and grab cluster settings
  become: yes
  become_user: "{{ kafka.user }}"
  command: "./aws_cluster_autodiscover {{ kafka.aws_cluster_autodiscover.hosts | join(',') }} {{ kafka.aws_cluster_autodiscover.r53_zone_id }} \"{{ kafka.aws_cluster_autodiscover.lookup_filter }}\" {{ kafka.aws_cluster_autodiscover.id_tag_name}}"
  args:
    chdir: "/home/{{ kafka.user }}/bin"
  register: aws_cluster_autodiscover
  until: aws_cluster_autodiscover | success
  retries: 2
  delay: 15
  when: kafka.aws_cluster_autodiscover.enabled

- name: Set cluster facts based on AWS autodiscover script output
  set_fact:
    kafka:
      aws_cluster_autodiscover:
        data: "{{ aws_cluster_autodiscover.stdout | from_json }}"
  when: kafka.aws_cluster_autodiscover.enabled

- name: Export broker ID to local file
  become: yes
  become_user: "{{ kafka.user }}"
  lineinfile:
    create: yes
    dest: "/home/{{ kafka.user }}/etc/brokerId"
    line: "{{ kafka.aws_cluster_autodiscover.data.id }}"
  when: kafka.aws_cluster_autodiscover.enabled

- name: Setup environment config
  become: yes
  become_user: "{{ kafka.user }}"
  template:
    dest: "/home/{{ kafka.user }}/etc/environment"
    mode: 0644
    src: environment.j2
  notify:
    - restart kafka

- name: Create log4j.properties
  become: yes
  become_user: "{{ kafka.user }}"
  template:
    dest: "/home/{{ kafka.user }}/etc/log4j.properties"
    mode: 0644
    src: log4j.properties.j2
  notify:
    - restart kafka

- name: Create server.properties
  become: yes
  become_user: "{{ kafka.user }}"
  template:
    dest: "/home/{{ kafka.user }}/etc/server.properties"
    mode: 0640
    src: server.properties.j2
  notify:
    - restart kafka

- name: Ensure Kafka is running
  become: yes
  service:
    name: kafka
    state: started
    
- name: Flush handlers to ensure Kafka is up to date
  meta: flush_handlers

- name: Wait for Kafka port
  wait_for:
    port: "{{ kafka.port }}"
    state: started
    timeout: 60

- name: Copy Kafka maintenance script
  become: yes
  become_user: "{{ kafka.user }}"
  copy:
    src: "kafka_maintenance"
    dest: "/home/{{ kafka.user }}/bin/kafka_maintenance"
    owner: "{{ kafka.user }}"
    group: "{{ kafka.group }}"
    mode: 0750

- name: Copy Kafka stop script
  become: yes
  copy:
    src: "stop_kafka"
    dest: "/etc/init.d"
    mode: 0755

- name: Add Kafka stop script to system runlevels
  become: yes
  file:
    src: "/etc/init.d/stop_kafka"
    dest: "/etc/{{ item }}/K10kafka-controlled-shutdown"
    state: link
    force: yes
  with_items:
    - "rc0.d"
    - "rc1.d"
    - "rc6.d"
